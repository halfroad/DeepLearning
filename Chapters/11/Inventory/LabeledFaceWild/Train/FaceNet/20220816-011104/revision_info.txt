arguments: FaceNet/src/train_softmax.py --logs_base_dir ../Inventory/LabeledFaceWild/Train/FaceNet/ --models_base_dir ../Inventory/LabeledFaceWild/Train/FaceNet/Models/FaceNet/ --data_dir ../Inventory/CustomizedDatasetsAligned/ --image_size 160 --model_def models.inception_resnet_v1 --lfw_dir ../Inventory/CustomizedDatasetsAligned/ --optimizer ADAM --learning_rate -1 --max_nrof_epochs 1 --keep_probability 0.8 --random_crop --random_flip --use_fixed_image_standardization --learning_rate_schedule_file FaceNet/data/learning_rate_schedule_classifier_casia.txt --weight_decay 5e-4 --embedding_size 512 --lfw_distance_metric 1 --lfw_use_flipped_images --lfw_subtract_mean --validation_set_split_ratio 0.05 --validate_every_n_epochs 5 --prelogits_norm_loss_factor 5e-4 --epoch_size 8 --lfw_batch_size 14 --lfw_pairs ../Inventory/Pairs/pairs.txt
--------------------
tensorflow version: 2.9.1
--------------------
git hash: b'cf08dba481378e34681659a3db6b7a891f714b9c'
--------------------
b'diff --git a/Chapters/11/11.1/FaceNet/src/classifier.py b/Chapters/11/11.1/FaceNet/src/classifier.py\nindex 749db4d6b..0602fe7f3 100644\n--- a/Chapters/11/11.1/FaceNet/src/classifier.py\n+++ b/Chapters/11/11.1/FaceNet/src/classifier.py\n@@ -26,7 +26,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n import argparse\n import facenet\ndiff --git a/Chapters/11/11.1/FaceNet/src/facenet.py b/Chapters/11/11.1/FaceNet/src/facenet.py\nindex a73e62336..f79d83b2a 100644\n--- a/Chapters/11/11.1/FaceNet/src/facenet.py\n+++ b/Chapters/11/11.1/FaceNet/src/facenet.py\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\n import tensorflow.compat.v1 as tf\n import numpy as np\n from scipy import misc\n+from matplotlib.pyplot import imread\n from sklearn.model_selection import KFold\n from scipy import interpolate\n from tensorflow.python.training import training\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\n     nrof_samples = len(image_paths)\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\n     for i in range(nrof_samples):\n-        img = misc.imread(image_paths[i])\n+        img = imread(image_paths[i])\n         if img.ndim == 2:\n             img = to_rgb(img)\n         if do_prewhiten:\ndiff --git a/Chapters/11/11.1/FaceNet/src/models/inception_resnet_v1.py b/Chapters/11/11.1/FaceNet/src/models/inception_resnet_v1.py\nindex 475e81bb4..9edcea40d 100644\n--- a/Chapters/11/11.1/FaceNet/src/models/inception_resnet_v1.py\n+++ b/Chapters/11/11.1/FaceNet/src/models/inception_resnet_v1.py\n@@ -23,8 +23,8 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n-import tensorflow.contrib.slim as slim\n+import tensorflow.compat.v1 as tf\n+import tf_slim as slim\n \n # Inception-Resnet-A\n def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\ndiff --git a/Chapters/11/11.1/FaceNet/src/train_softmax.py b/Chapters/11/11.1/FaceNet/src/train_softmax.py\nindex 6b0b28b58..01eefdab9 100644\n--- a/Chapters/11/11.1/FaceNet/src/train_softmax.py\n+++ b/Chapters/11/11.1/FaceNet/src/train_softmax.py\n@@ -31,7 +31,7 @@ import os.path\n import time\n import sys\n import random\n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n import importlib\n import argparse\n@@ -39,7 +39,7 @@ import facenet\n import lfw\n import h5py\n import math\n-import tensorflow.contrib.slim as slim\n+import tf_slim as slim\n from tensorflow.python.ops import data_flow_ops\n from tensorflow.python.framework import ops\n from tensorflow.python.ops import array_ops\n@@ -415,6 +415,9 @@ def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phas\n     sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\n     \n     embedding_size = int(embeddings.get_shape()[1])\n+    \n+    print("nrof_images = {}, batch_size = {}".format(nrof_images, batch_size))\n+        \n     assert nrof_images % batch_size == 0, \'The number of LFW images must be an integer multiple of the LFW batch size\'\n     nrof_batches = nrof_images // batch_size\n     emb_array = np.zeros((nrof_images, embedding_size))\n@@ -573,6 +576,7 @@ def parse_arguments(argv):\n         help=\'Concatenates embeddings for the image and its horizontally flipped counterpart.\', action=\'store_true\')\n     parser.add_argument(\'--lfw_subtract_mean\', \n         help=\'Subtract feature mean before calculating distance.\', action=\'store_true\')\n+            \n     return parser.parse_args(argv)\n   \n \ndiff --git a/Chapters/11/11.1/FaceRecognitionWithFaceNet.py b/Chapters/11/11.1/FaceRecognitionWithFaceNet.py\nindex 3802da147..eac5a78ef 100644\n--- a/Chapters/11/11.1/FaceRecognitionWithFaceNet.py\n+++ b/Chapters/11/11.1/FaceRecognitionWithFaceNet.py\n@@ -156,6 +156,14 @@ def SwitchEnvironmentVariables():\n     \n      python3 FaceNet/src/validate_on_lfw.py ../Inventory/Aligned  /Users/jinhui/Projects/DeepLearning/Chapters/11/Inventory/Models/20180402-114759.pb --distance_metric 1 --use_flipped_images --subtract_mean --use_fixed_image_standardization --lfw_pairs /Users/jinhui/Projects/DeepLearning/Chapters/11/11.1/FaceNet/data/pairs.txt\n      \n+     python3 FaceNet/src/classifier.py TRAIN ../Inventory/CustomizedDatasets /Users/jinhui/Projects/DeepLearning/Chapters/11/Inventory/Models/20180402-114759.pb ../Inventory/Models/OwnedClassifier.pkl --image_size 160\n+     \n+     GeneratePairs.py: https://github.com/VictorZhang2014/facenet/blob/master/mydata/generate_pairs.py\n+     \n+     python3 FaceNet/src/train_softmax.py --logs_base_dir ../Inventory/LabeledFaceWild/Train/FaceNet/ --models_base_dir ../Inventory/LabeledFaceWild/Train/FaceNet/Models/FaceNet/ --data_dir ../Inventory/CustomizedDatasetsAligned/ --image_size 160 --model_def models.inception_resnet_v1 --lfw_dir ../Inventory/CustomizedDatasetsAligned/ --optimizer ADAM --learning_rate -1 --max_nrof_epochs 1 --keep_probability 0.8 --random_crop --random_flip --use_fixed_image_standardization --learning_rate_schedule_file FaceNet/data/learning_rate_schedule_classifier_casia.txt --weight_decay 5e-4 --embedding_size 512 --lfw_distance_metric 1 --lfw_use_flipped_images --lfw_subtract_mean --validation_set_split_ratio 0.05 --validate_every_n_epochs 5 --prelogits_norm_loss_factor 5e-4 --epoch_size 8 --lfw_batch_size 16 --lfw_pairs ../Inventory/Pairs/pairs.txt\n+     \n+     python3 FaceNet/src/validate_on_lfw.py ../Inventory/CustomizedDatasetsAligned ../Inventory/LabeledFaceWild/Train/FaceNet/Models/FaceNet/20220816-000939 --lfw_pairs ../Inventory/Pairs/pairs.txt --lfw_batch_size 2 --image_size 160 --distance_metric 1 --use_flipped_images --subtract_mean --use_fixed_image_standardization\n+     \n     \'\'\'\n \n \ndiff --git a/Chapters/11/11.1/GeneratePairs.py b/Chapters/11/11.1/GeneratePairs.py\nindex 7a12eac86..0f917857b 100644\n--- a/Chapters/11/11.1/GeneratePairs.py\n+++ b/Chapters/11/11.1/GeneratePairs.py\n@@ -1,68 +1,79 @@\n-import sys\n+#! encoding: utf-8\n+\n import os\n import random\n-import time\n-import itertools\n-import pdb\n-import argparse\n-\n-\n-\n-\n-parser = argparse.ArgumentParser(description=\'generate image pairs\')\n-\n-parser.add_argument(\'--data-dir\', default=\'\', help=\'\')\n-parser.add_argument(\'--outputtxt\', default=\'\', help=\'path to save.\')\n-parser.add_argument(\'--num-samepairs\',default=100)\n-args = parser.parse_args()\n-cnt = 0\n-same_list = []\n-diff_list = []\n-list1 = []\n-list2 = []\n-folders_1 = os.listdir(args.data_dir)\n-dst = open(args.outputtxt, \'a\')\n-count = 0\n-dst.writelines(\'\\n\')\n-\n-for folder in folders_1:\n-    sublist = []\n-    same_list = []\n-    imgs = os.listdir(os.path.join(args.data_dir, folder))\n-    for img in imgs:\n-        img_root_path = os.path.join(args.data_dir, folder, img)\n-        sublist.append(img_root_path)\n-        list1.append(img_root_path)\n-    for item in itertools.combinations(sublist, 2):\n-        for name in item:\n-            same_list.append(name)\n-    if len(same_list) > 10 and len(same_list) < 13:\n-        for j in range(0, len(same_list), 2):\n-                if count < int(args.num_samepairs):\n-                    dst.writelines(same_list[j] + \' \' + same_list[j+1]+ \' \' + \'1\' + \'\\n\')\n-                    count += 1\n-    if count >= int(args.num_samepairs):\n-        break\n-list2 = list1.copy()\n-\n-\n-\n-diff = 0\n-print(count)\n-\n-\n-while True:\n-    random.seed(time.time() * 100000 % 10000)\n-    random.shuffle(list2)\n-    for p in range(0, len(list2) - 1, 2):\n-        if list2[p] != list2[p + 1]:\n-            dst.writelines(list2[p] + \' \' + list2[p + 1] + \' \' + \'0\'+ \'\\n\')\n-            diff += 1\n-            if diff >= count:\n-                break\n-            \n-    if diff < count:\n-        \n-        continue\n-    else:\n-        break\n+\n+class GeneratePairs:\n+    """\n+    Generate the pairs.txt file that is used for training face classifier when calling python `src/train_softmax.py`.\n+    Or others\' python scripts that needs the file of pairs.txt.\n+\n+    Doc Reference: http://vis-www.cs.umass.edu/lfw/README.txt\n+    """\n+\n+    def __init__(self, data_dir, pairs_filepath, img_ext):\n+        """\n+        Parameter data_dir, is your data directory.\n+        Parameter pairs_filepath, where is the pairs.txt that belongs to.\n+        Parameter img_ext, is the image data extension for all of your image data.\n+        """\n+        self.data_dir = data_dir\n+        self.pairs_filepath = pairs_filepath\n+        self.img_ext = img_ext\n+\n+\n+    def generate(self):\n+        self._generate_matches_pairs()\n+        self._generate_mismatches_pairs()\n+\n+\n+    def _generate_matches_pairs(self):\n+        """\n+        Generate all matches pairs\n+        """\n+        for name in os.listdir(self.data_dir):\n+            if name == ".DS_Store":\n+                continue\n+\n+            a = []\n+            for file in os.listdir(self.data_dir + name):\n+                if file == ".DS_Store":\n+                    continue\n+                a.append(file)\n+\n+            with open(self.pairs_filepath, "a") as f:\n+                for i in range(3):\n+                    temp = random.choice(a).split("_") # This line may vary depending on how your images are named.\n+                    w = temp[0] + "_" + temp[1]\n+                    l = random.choice(a).split("_")[2].lstrip("0").rstrip(self.img_ext)\n+                    r = random.choice(a).split("_")[2].lstrip("0").rstrip(self.img_ext)\n+                    f.write(w + "\\t" + l + "\\t" + r + "\\n")\n+\n+\n+    def _generate_mismatches_pairs(self):\n+        """\n+        Generate all mismatches pairs\n+        """\n+        for i, name in enumerate(os.listdir(self.data_dir)):\n+            if name == ".DS_Store":\n+                continue\n+\n+            remaining = os.listdir(self.data_dir)\n+            remaining = [f_n for f_n in remaining if f_n != ".DS_Store"]\n+            # del remaining[i] # deletes the file from the list, so that it is not chosen again\n+            other_dir = random.choice(remaining)\n+            with open(self.pairs_filepath, "a") as f:\n+                for i in range(3):\n+                    file1 = random.choice(os.listdir(self.data_dir + name))\n+                    file2 = random.choice(os.listdir(self.data_dir + other_dir))\n+                    f.write(name + "\\t" + file1.split("_")[2].lstrip("0").rstrip(self.img_ext) + "\\t")\n+                f.write("\\n")\n+\n+\n+if __name__ == \'__main__\':\n+    data_dir = "../Inventory/CustomizedDatasets/"\n+    pairs_filepath = "../Inventory/Pairs/pairs.txt"\n+    img_ext = ".jpg"\n+    generatePairs = GeneratePairs(data_dir, pairs_filepath, img_ext)\n+    generatePairs.generate()\n+'